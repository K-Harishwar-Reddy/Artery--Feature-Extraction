{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ef57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# import necessary packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import ast\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WSI = \"/Users/jinzhou/Desktop/USCAP/data/wsi\"\n",
    "DIR_ANN = \"/Users/jinzhou/Desktop/USCAP/data/ann_geojsons\"\n",
    "DIR_SAVE = \"/Users/jinzhou/Desktop/USCAP/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed207ed",
   "metadata": {},
   "source": [
    "## Process thickness.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7efd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_STAT = os.path.join(DIR_SAVE, \"thickness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8786e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read thickness analysis\n",
    "def read_df_from_csv(path_csv):\n",
    "    df = pd.read_csv(path_csv)\n",
    "    # original list in path_csv is read as string, for example \"[0.2, 0.1, ...]\"\n",
    "    # ast.literal_eval converts string to python literal structures\n",
    "    df['Thickness_Media_Abs'] = df['Thickness_Media_Abs'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['Thickness_Intima_Abs'] = df['Thickness_Intima_Abs'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['Thickness_Wall_Abs'] = df['Thickness_Wall_Abs'].apply(lambda x: ast.literal_eval(x))\n",
    "    return df\n",
    "\n",
    "df_thick = read_df_from_csv(PATH_STAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067fc99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A few adjustment to match qupath annotations to labels assignment\n",
    "# 1. In \"11_26609_023_512 L4 TRI\", A8 -> A08\n",
    "# 2. In \"11_26609_009_008 L10 TRI\", there are two A26, where the second one should be A27\n",
    "# 3. discard \"12_26609_021_507 L03 TRI\" from analysis\n",
    "\n",
    "df_thick.loc[:, 'Artery_ID'] = df_thick.loc[:, 'Artery_ID'].str.split('_').str[0]\n",
    "\n",
    "df_thick.loc[(df_thick.loc[:, 'WSI_ID'] == '11_26609_009_008 L10 TRI') & \n",
    "       (df_thick.loc[:, 'Artery_ID'] == 'A26'), 'Artery_ID'] = ['A26', 'A27']\n",
    "\n",
    "df_thick.loc[(df_thick.loc[:, 'WSI_ID'] == '11_26609_023_512 L4 TRI') & \n",
    "       (df_thick.loc[:, 'Artery_ID'] == 'A8'), 'Artery_ID'] = 'A08'\n",
    "\n",
    "df_thick = df_thick[df_thick.loc[:, \"WSI_ID\"]!=\"12_26609_021_507 L03 TRI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7099bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and WSI_Artery_ID, ignoring media and intima index\n",
    "df_thick.loc[:, 'WSI_Artery_ID'] = df_thick.loc[:, 'WSI_ID'] + '_' \\\n",
    "    + df_thick.loc[:, 'Artery_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24615c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For arteries with multiple lumen/intima areas, we pick the one with maxium lumen area\n",
    "df_thick = df_thick.sort_values('Area', ascending=False).drop_duplicates(['WSI_Artery_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7c19",
   "metadata": {},
   "source": [
    "## Process \"Labels.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_LABEL = \"/Users/jinzhou/Desktop/USCAP/data/raw/labels_updated.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.ExcelFile(PATH_LABEL)\n",
    "\n",
    "# Only read the first sheet of the excel file\n",
    "sheet_name = df_label.sheet_names[0]\n",
    "df_label = df_label.parse(sheet_name, skiprows=1) # skip the first row\n",
    "# Use Artery_ID as row index and WSI_ID as column name\n",
    "df_label = df_label.rename(columns = {'Unnamed: 0':'Artery_ID'}).set_index(\"Artery_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace labels of strings to integers.\n",
    "df_label = df_label.replace({\"without arteriosclerosis\": 0, \n",
    "                             \"mild arteriosclerosis\": 1, \n",
    "                             \"mild hyalinosis\": 1, \n",
    "                             \"moderate arteriosclerosis\": 2,\n",
    "                             \"severe arteriosclerosis\": 3, \n",
    "                             \"-\": np.nan, \" - \": np.nan})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11df52",
   "metadata": {},
   "source": [
    "## Clip and Normalize Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb814ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_w_two_list(thickness_outer, thickness_inner, xlabel, excludes, path_to_svae):\n",
    "    for val in excludes:\n",
    "        thickness_outer = [x for x in thickness_outer if x!=val]\n",
    "        thickness_inner = [x for x in thickness_inner if x!=val]\n",
    "    bins = np.linspace(0, np.max(thickness_outer+thickness_inner), 100)\n",
    "    plt.figure(figsize=(10, 5))    \n",
    "    plt.hist(thickness_outer, bins=bins, alpha=0.5, label=\"Media\") \n",
    "    plt.hist(thickness_inner, bins=bins, alpha=0.5, label=\"Intima\")\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(xlabel, fontsize=20)\n",
    "    plt.ylabel(\"Frequency\", fontsize=20)\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    if path_to_svae:\n",
    "        plt.savefig(path_to_svae)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def clip_normalize(thick_media, thick_intima, thick_wall, plot_hist=False):\n",
    "    assert len(thick_media) == len(thick_intima) == len(thick_wall) == 360\n",
    "    \n",
    "    # visualize hist before processing\n",
    "    if plot_hist:\n",
    "        plot_hist_w_two_list(thick_media, thick_intima, \"Thickness\", [-1], None)\n",
    "    # Clip by 0.05 * median value of  thick_wall\n",
    "    # remove all -1s, -1 means not intersection/thickness was found at this sample    \n",
    "    clip_th = 0.05*np.median([x for x in thick_wall if x!= -1])\n",
    "    thick_media_norm = [-1]*len(thick_media)\n",
    "    thick_intima_norm = [-1]*len(thick_intima)\n",
    "    for i in range(len(thick_wall)):\n",
    "        if thick_media[i] < clip_th or thick_intima[i] < clip_th: \n",
    "            # if either media or intima thickness is below threshold, discard both\n",
    "            continue\n",
    "        else:\n",
    "            thick_media_norm[i] = thick_media[i] / thick_wall[i]\n",
    "            thick_intima_norm[i] = thick_intima[i] / thick_wall[i]\n",
    "    thick_media_norm = [x for x in thick_media_norm if x!=-1]\n",
    "    thick_intima_norm = [x for x in thick_intima_norm if x!=-1]\n",
    "    if plot_hist:\n",
    "        plot_hist_w_two_list(thick_media_norm, thick_intima_norm, \n",
    "                             \"Clipped and Normalizied Thickness\", [], plot_hist)\n",
    "    return thick_media_norm, thick_intima_norm\n",
    "\n",
    "def get_features(dict_features, l_thick, prefix): \n",
    "    arr_thick = np.array(sorted(l_thick, reverse=True))\n",
    "    # average of the top 5% value\n",
    "    dict_features[prefix+\" Average of Top 5%\"] = np.mean(arr_thick[:len(arr_thick)//20])\n",
    "    dict_features[prefix+\" Skewness\"] = scipy.stats.skew(arr_thick)\n",
    "    dict_features[prefix+\" Power\"] = scipy.sum(arr_thick**2)/arr_thick.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35708a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features_label = pd.DataFrame(columns = [\"WSI_Artery_ID\", \"Media Average of Top 5%\", \"Media Skewness\", \"Media Power\", \n",
    "                                             \"Intima Average of Top 5%\", \"Intima Skewness\", \"Intima Power\",\n",
    "                                             \"Label\"])\n",
    "\n",
    "for index, row in df_thick.iterrows():\n",
    "    thick_media = row[\"Thickness_Media_Abs\"]\n",
    "    thick_intima = row[\"Thickness_Intima_Abs\"]\n",
    "    thick_wall = row[\"Thickness_Wall_Abs\"]\n",
    "    path_save_hist = os.path.join(DIR_SAVE, row[\"WSI_ID\"], row[\"Artery_ID\"]+\"_hist.png\")\n",
    "    \n",
    "    # clip and normalize\n",
    "    thick_media, thick_intima = clip_normalize(thick_media = row[\"Thickness_Media_Abs\"], \n",
    "                                               thick_intima = row[\"Thickness_Intima_Abs\"], \n",
    "                                               thick_wall = row[\"Thickness_Wall_Abs\"], plot_hist=None)\n",
    "    # feature extraction\n",
    "    row_features_label = {}\n",
    "    features_media = get_features(row_features_label, thick_media, \"Media\")\n",
    "    features_intima = get_features(row_features_label, thick_intima, \"Intima\")\n",
    "    row_features_label[\"WSI_Artery_ID\"] = row[\"WSI_Artery_ID\"]\n",
    "    row_features_label[\"Label\"] = df_label.loc[row[\"Artery_ID\"], row[\"WSI_ID\"]]\n",
    "    df_features_label = df_features_label.append(row_features_label, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e73a06",
   "metadata": {},
   "source": [
    "## HeatMap, Boxtplot and Kendall Tau Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77705504",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def heatmap_features(df_features_label, feature_name):\n",
    "    xticklabels = df_features_label.loc[:, \"WSI_Artery_ID\"].values\n",
    "    features = df_features_label.loc[:, feature_name].values\n",
    "    labels = df_features_label.loc[:, \"Label\"].values\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(24, 4))\n",
    "    axs = fig.subplot_mosaic([['TopLeft', 'Right'],['BottomLeft', 'Right']],\n",
    "                              gridspec_kw={'width_ratios':[5, 1]})\n",
    "    \n",
    "    # heatmap\n",
    "    idx_sort = features.argsort()\n",
    "    sns.heatmap(features[idx_sort].reshape(1, -1), cbar=True, \n",
    "                cbar_kws = dict(use_gridspec=False,location=\"bottom\"), \n",
    "                ax=axs['TopLeft'])\n",
    "    axs['TopLeft'].set_xticks([])\n",
    "    axs['TopLeft'].set_yticks([])\n",
    "    axs['TopLeft'].set_ylabel(\"Feature\", fontsize=15)\n",
    "    sns.heatmap(labels[idx_sort].reshape(1, -1), cmap='gray', cbar=True, \n",
    "                cbar_kws = dict(use_gridspec=False,location=\"bottom\"), \n",
    "#                 xticklabels =xticklabels[idx_sort] ,\n",
    "                ax=axs['BottomLeft'])\n",
    "    axs['BottomLeft'].set_xticks([])\n",
    "    axs['BottomLeft'].set_yticks([])\n",
    "    axs['BottomLeft'].set_ylabel(\"Score\", fontsize=15)\n",
    "    idx_label_0 = labels==0\n",
    "    idx_label_1 = labels==1\n",
    "    idx_label_2 = labels==2\n",
    "    idx_label_3 = labels==3\n",
    "    \n",
    "    # box plot\n",
    "    features_label_0 = features[idx_label_0]\n",
    "    features_label_1 = features[idx_label_1]\n",
    "    features_label_2 = features[idx_label_2]\n",
    "    features_label_3 = features[idx_label_3]\n",
    "    axs['Right'].boxplot([features_label_0, features_label_1, features_label_2, features_label_3])\n",
    "    axs['Right'].set_xticklabels([0,1,2,3], fontsize=12)  \n",
    "    axs['Right'].tick_params(axis=\"y\", labelsize=12)\n",
    "    axs['Right'].set_xlabel(\"Arteriosclerosis Score\", fontsize=15)\n",
    "    axs['Right'].set_ylabel(\"Feature\", fontsize=15)\n",
    "    \n",
    "    # Kendall Tau\n",
    "    rho, p_val = scipy.stats.kendalltau(features, labels)\n",
    "    plt.show()\n",
    "    print('Feature: {}; kendalltau: rho = {:.2f}, p = {:.6f}'.format(feature_name, rho, p_val))\n",
    "    \n",
    "for col in [\"Media Average of Top 5%\", \"Media Skewness\", \"Media Power\", \n",
    "            \"Intima Average of Top 5%\", \"Intima Skewness\", \"Intima Power\"]:\n",
    "    heatmap_features(df_features_label, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5381a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join(DIR_SAVE, \"features_label.csv\")\n",
    "df_features_label.to_csv(path_to_save, index=False)  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
